<!DOCTYPE html>
<html>
<head>
<style>

body {
    background-color: #f7f1e3;
    font-family: Arial, sans-serif;

    line-height: 1.3;
    text-align: justify;

    font-size: 13px;
}

p {
    font-family: Georgia, serif
}

.container {
    padding:20px;
    padding-left: 60px;
    max-width: 600px;

    color: #2f3640;

    opacity: 0;
    animation-name: fadeIn;
    animation-duration: 3s;
    animation-iteration-count: 1;
    animation-fill-mode: forwards;
    }

.email {
    font-family: 'Courier New', monospace;
}

a:link{
  color:#227093;
}

a:visited{
  color:#227093;
}

.collapsible {
  cursor: pointer;
  /*padding: 5px;*/
  border: none;
  margin-left:-5px;
  text-align: left;
  outline: none;
  font-size: 18px;
  font-weight: bold;
  background-color: inherit;
}

/* Add a background color to the button if it is clicked on (add the .active class with JS), and when you move the mouse over it (hover) */
.collapsible:hover {
  background-color: rgb(220, 118, 118);
}

/* Style the collapsible content. Note: hidden by default */
.content {
  display: none;
  overflow: hidden;
}

@keyframes fadeIn {
  from {
    opacity: 0;
  }
  
  to {
    opacity: 1;
  }
}

</style>

<script src="https://code.jquery.com/jquery-1.9.1.min.js"></script>
<script>
$( document ).ready(function() {

    $( ".collapsible" ).on( "click", function() {
        col = $(this);
        $( ".content" ).toggle("fast", function() {
            if ( $(this).is(":hidden") ) {
                console.log("here2")
                col.text('Publications +');
            } else {
                console.log("here")
                col.text('Publications -');
            };
        });
    });

});
</script>


</head>
<body>

<div class="container">

<h1>Andrew Loren Bell</h1>

<div class="email">{alb9742}@nyu.edu, {me,andrew}@andrewbell.io</div>

<p>I am a Computer Science Ph.D. Candidate at the New York University <a target="_blank" href="https://airesponsibly.net/">Center for Responsbile AI</a>, co-advised by <a target="_blank" href="https://stoyanovich.org/">Dr. Julia Stoyanovich</a> and <a target="_blank" href="https://wp.nyu.edu/odednov/">Dr. Oded Nov</a>.
    I am a recipient of the National Science Foundation Graduate Research Fellowship (NSF GRFP).
    My research interests lie at the intersection of machine learning and public policy, and are more narrowly focused on the fairness and explainability of AI systems.
    In Spring 2023, I was a visiting research fellow at the <a target="_blank" href="https://centai.eu/home">Center for AI (CENTAI)</a> in Turin, Italy.
</p>
<p>I was a fellow at <a target="_blank" href="https://www.dssgfellowship.org/">Data Science for Social Good</a> and a project manager at <a target="_blank" href="https://solveforgood.org/">Solve for Good</a>, where I worked on major policy projects, like parterning with a European country’s national government to develop machine learning models for identifying children at <a target="_blank" href="https://doi.org/10.1109/ICHI.2019.8904616">risk of not being vaccinated for Measles, Mumps and Rubella</a>.
    I also worked at the policy research institute <a target="_blank" href="https://www.mdrc.org">MDRC</a>.
    I graduated from the <a target="_blank" href="https://www.clemson.edu/cuhonors/index.html">Honors College at Clemson University</a> with a Bachelor’s degree in Mathematics.
</p>

<button type="button" class="collapsible">Publications +</button> 
<div class="content">
<p>
    [link] <b>Bell, Andrew</b> and Julia Stoyanovich. "Making transparency influencers: a case atudy of an aducational approach to improve responsible AI practices in news and media." In <i>Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems</i> (forthcoming).
</p>

<p>
    [<a target="_blank" href="https://arxiv.org/abs/2401.16088">link</a>] <b>Bell, Andrew*</b>, João Fonseca*, Carlo Abrate, Francesco Bonchi, and Julia Stoyanovich. "Fairness in algorithmic recourse through the lens of substantive equality of opportunity." <i>Under review.</i> 2024.
</p>

<p>
    [<a target="_blank" href="https://dl.acm.org/doi/pdf/10.1145/3617694.3623251">link</a>] <b>Best AI Paper Award.</b> Fonseca*, João, <b>Andrew Bell*</b>, Carlo Abrate, Francesco Bonchi, and Julia Stoyanovich. "Setting the right expectations: algorithmic recourse over time." In <i>Proceedings of the 3rd ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization</i>, pp. 1-11. 2023.
</p>

<p>
    [<a target="_blank" href="https://dl.acm.org/doi/pdf/10.1145/3593013.3594007">link</a>] <b>Bell, Andrew</b>, Lucius Bynum, Nazarii Drushchak, Tetiana Zakharchenko, Lucas Rosenblatt, and Julia Stoyanovich. "The possibility of fairness: revisiting the impossibility theorem in practice." In <i>Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency</i>, pp. 400-422. 2023.
</p>

<p>
    [<a target="_blank" href="https://www.cambridge.org/core/journals/data-and-policy/article/think-about-the-stakeholders-first-toward-an-algorithmic-transparency-playbook-for-regulatory-compliance/10D7F194DB250DDF3A30471B5CEB9326?utm_campaign=shareaholic&utm_medium=copy_link&utm_source=bookmark">link</a>] <b>Bell, Andrew</b>, Oded Nov, and Julia Stoyanovich. "Think about the stakeholders first! Toward an algorithmic transparency playbook for regulatory compliance." <i>Data & Policy 5</i> (2023): e12.
</p>

<p>
    [<a target="_blank" href="https://dl.acm.org/doi/pdf/10.1145/3544549.3574169">link</a>] <b>Bell, Andrew</b>, Oded Nov, and Julia Stoyanovich. "The algorithmic transparency playbook: a stakeholder-first approach to creating transparency for your organization’s algorithms." In <i>Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems</i>, pp. 1-4. 2023.
</p>

<p>
    [<a target="_blank" href="https://dl.acm.org/doi/pdf/10.1145/3531146.3533090">link</a>] <b>Bell, Andrew</b>, Ian Solano-Kamaiko, Oded Nov, and Julia Stoyanovich. "It’s just not that simple: an empirical study of the accuracy-explainability trade-off in machine learning for public policy." In <i>Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency</i>, pp. 248-266. 2022.
</p>

<p>
    [<a target="_blank" href="https://doi.org/10.1080/19345747.2019.1634169">link</a>] Bloom, Howard, <b>Andrew Bell</b>, and Kayla Reiman. "Using data from randomized trials to assess the likely generalizability of educational treatment-effect estimates from regression discontinuity designs." <i>Journal of Research on Educational Effectiveness 13</i>, no. 3 (2020): 488-517.
</p>

<p>
    [<a target="_blank" href="https://doi.org/10.1525/gp.2020.12908">link</a>] Zejnilović, Leid, Susana Lavado, Íñigo Martínez de Rituerto de Troya, Samantha Sim, and <b>Andrew Bell</b>. "Algorithmic long-term unemployment risk assessment in use: counselors’ perceptions and use practices." <i>Global Perspectives 1</i>, no. 1 (2020): 12908.
</p>

<p>
    [<a target="_blank" href="https://doi.org/10.5465/AMBPP.2021.264">link</a>] Zejnilovic, Leid, Susana Lavado, Carlos Soares, Íñigo Martínez De Rituerto De Troya, <b>Andrew Bell</b>, and Rayid Ghani. "Machine learning informed decision-making with interpreted model’s outputs: A field intervention." In <i>Academy of Management Proceedings</i>, vol. 2021, no. 1, p. 15424. Briarcliff Manor, NY 10510: Academy of Management, 2021.
</p>

<p>
    [<a target="_blank" href="https://doi.org/10.1109/ICHI.2019.8904616">link</a>] <b>Bell, Andrew</b>, Alexander Rich, Melisande Teng, Tin Orešković, Nuno B. Bras, Lénia Mestrinho, Srdan Golubovic, Ivan Pristas, and Leid Zejnilovic. "Proactive advising: a machine learning driven approach to vaccine hesitancy." In <i>Proceedings of 2019 IEEE International Conference on Healthcare Informatics (ICHI)</i>, pp. 1-6. IEEE, 2019.
</p>

<p>
    * Equal contribution by authors
</p>
</div>
</div>

</body>
</html>
